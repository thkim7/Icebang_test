import torch
from transformers import AutoTokenizer, AutoModel
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

class HybridMatcher:
    def __init__(self):
        try:
            # í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ìš°ì„  ì‹œë„
            self.tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')
            self.model = AutoModel.from_pretrained('klue/bert-base')
            print("âœ… KLUE BERT ëª¨ë¸ ë¡œë”© ì„±ê³µ")
        except Exception as e:
            print(f"KLUE BERT ì‹¤íŒ¨: {e}")
            try:
                # ë‹¤êµ­ì–´ ëª¨ë¸ë¡œ ëŒ€ì²´
                self.tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')
                self.model = AutoModel.from_pretrained('bert-base-multilingual-cased')
                print("âœ… ë‹¤êµ­ì–´ BERT ëª¨ë¸ ë¡œë”© ì„±ê³µ")
            except Exception as e2:
                print(f"ëª¨ë“  BERT ëª¨ë¸ ì‹¤íŒ¨: {e2}")
                raise e2
    
    def get_embedding(self, text):
        """í…ìŠ¤íŠ¸ë¥¼ BERT ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)
        with torch.no_grad():
            outputs = self.model(**inputs)
        # [CLS] í† í°ì˜ ì„ë² ë”© ì‚¬ìš©
        return outputs.last_hidden_state[:, 0, :].numpy()
    
    def get_similarity(self, text1, text2):
        """ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        embedding1 = self.get_embedding(text1)
        embedding2 = self.get_embedding(text2)
        return cosine_similarity(embedding1, embedding2)[0][0]
    
    def is_related_product(self, title, keyword, bert_threshold=0.7, debug=False):
        """
        ê°œì„ ëœ í•˜ì´ë¸Œë¦¬ë“œ ë¡œì§ìœ¼ë¡œ ê´€ë ¨ ìƒí’ˆ íŒë‹¨
        1. í‚¤ì›Œë“œê°€ ìƒí’ˆëª…ì— ì§ì ‘ í¬í•¨ë˜ë©´ ê´€ë ¨ ìƒí’ˆìœ¼ë¡œ íŒë‹¨ (ê°€ì¥ ë†’ì€ ìš°ì„ ìˆœìœ„)
        2. BERT ìœ ì‚¬ë„ ì ìˆ˜ê°€ ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ ê´€ë ¨ ìƒí’ˆìœ¼ë¡œ íŒë‹¨
        """
        
        # ë„ì–´ì“°ê¸° ì—†ì´ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸ (1ë‹¨ê³„)
        normalized_title = title.replace(' ', '')
        normalized_keyword = keyword.replace(' ', '')
        
        if normalized_keyword in normalized_title:
            if debug:
                print(f"âœ… ê´€ë ¨ìƒí’ˆ | í‚¤ì›Œë“œ ì¼ì¹˜ | ìƒí’ˆëª…: '{title}'")
            return True, "í‚¤ì›Œë“œ ì¼ì¹˜"

        # BERT ìœ ì‚¬ë„ ê³„ì‚° (2ë‹¨ê³„)
        similarity = self.get_similarity(title, keyword)

        if debug:
            print(f"    í‚¤ì›Œë“œ: '{keyword}'")
            print(f"    ìƒí’ˆëª…: '{title}'")
            print(f"    ìœ ì‚¬ë„: {similarity:.4f}")
            
        if similarity >= bert_threshold:
            if debug:
                print(f"âœ… ê´€ë ¨ìƒí’ˆ | BERT ìœ ì‚¬ë„ {similarity:.4f} > {bert_threshold}")
            return True, f"BERT ìœ ì‚¬ë„ {similarity:.4f}"
        else:
            if debug:
                print(f"âŒ ë¬´ê´€ìƒí’ˆ | ìœ ì‚¬ë„ {similarity:.4f} (ê¸°ì¤€ ë¯¸ë‹¬)")
            return False, f"ìœ ì‚¬ë„ {similarity:.4f} (ê¸°ì¤€ ë¯¸ë‹¬)"

def run_tests():
    matcher = HybridMatcher()
    
    # ë” ëª…í™•í•˜ê²Œ êµ¬ë¶„ë˜ëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases_refined = [
        {
            "keyword": "ì½œë¼ê²ë§ˆìŠ¤í¬íŒ©",
            "products": [
                # âœ… ê´€ë ¨ ìƒí’ˆ
                ("Wei Xueì˜ ë™ì¼í•œ ì½œë¼ê² ê¸€ë£¨ì½”ìŠ¤ì•„ë¯¼ ìœ ì—° ìŠ¤í‚¨ ë§ˆìŠ¤í¬", True),
                ("V ì–¼êµ´ ë§ˆìŠ¤í¬ ì½œë¼ê² ë¹¨ê°„ ë³‘ ë¦¬í”„íŒ… í˜ì´ìŠ¤ í˜ì´ë“œ ì»¤íŒ… í¼íŒ… ë§ˆìŠ¤í¬", True),
                ("í”„ë¦¬ë¯¸ì—„ ì½œë¼ê² í˜ì´ì…œ ë§ˆìŠ¤í¬ 10ë§¤", True),
                ("ì½œë¼ê²ë§ˆìŠ¤í¬íŒ© 100ì¥ (ì§ì ‘ í‚¤ì›Œë“œ í¬í•¨)", True),
                
                # âŒ ë¬´ê´€ ìƒí’ˆ (BERTê°€ í˜¼ë™í–ˆë˜ ìœ í˜• + ëª…í™•íˆ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬)
                ("íˆì•Œë£¨ë¡ ì‚° ìˆ˜ë¶„ ì•°í”Œ 100ml ëŒ€ìš©ëŸ‰", False),
                ("ë¹„íƒ€ë¯¼C ë¸Œë¼ì´íŠ¸ë‹ ì„¸ëŸ¼", False),
                ("ì²œì—° í—ˆë¸Œ í´ë Œì§• í¼", False),
                ("ì• í”Œì›Œì¹˜ 8ì„¸ëŒ€ 45mm ì¼€ì´ìŠ¤", False),
            ]
        },
        {
            "keyword": "ë¬´ì„ ì´ì–´í°",
            "products": [
                # âœ… ê´€ë ¨ ìƒí’ˆ
                ("ì• í”Œ ì—ì–´íŒŸ í”„ë¡œ ë¬´ì„  ì´ì–´í° 3ì„¸ëŒ€", True),
                ("ì‚¼ì„± ê°¤ëŸ­ì‹œ ë²„ì¦ˆ ë¸”ë£¨íˆ¬ìŠ¤ ì´ì–´í°", True), 
                ("ì†Œë‹ˆ ì™„ì „ë¬´ì„ ì´ì–´í° ë…¸ì´ì¦ˆìº”ìŠ¬ë§", True),
                
                # âŒ ë¬´ê´€ ìƒí’ˆ
                ("ì  í•˜ì´ì € ìœ ì„  ì´ì–´í° ê³ ìŒì§ˆ", False),
                ("JBL ë¸”ë£¨íˆ¬ìŠ¤ ìŠ¤í”¼ì»¤ íœ´ëŒ€ìš©", False),
                ("ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ë¬´ì„  ë§ˆìš°ìŠ¤", False),
                ("ì•„ì´í° ì¶©ì „ê¸° ì¼€ì´ë¸”", False),
            ]
        },
    ]

    print("=" * 80)
    print("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ í‚¤ì›Œë“œ ë§¤ì¹­ í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    print("=" * 80)
    
    bert_thresholds = [0.6, 0.7, 0.8]
    for threshold in bert_thresholds:
        print(f"\nğŸ“Š BERT ìœ ì‚¬ë„ ì„ê³„ê°’: {threshold}")
        print("-" * 60)
        
        total_correct = 0
        total_cases = 0
        
        for case in test_cases_refined:
            keyword = case["keyword"]
            print(f"\nğŸ” í‚¤ì›Œë“œ: '{keyword}'")
            
            for title, expected in case["products"]:
                is_related, reason = matcher.is_related_product(title, keyword, bert_threshold=threshold)
                predicted = is_related
                is_correct = (predicted == expected)
                
                status = "âœ…" if is_correct else "âŒ"
                print(f"  {status} {'ê´€ë ¨' if predicted else 'ë¬´ê´€'} (ê¸°ëŒ€: {'ê´€ë ¨' if expected else 'ë¬´ê´€'}) | {title[:40]} | {reason}")
                
                total_correct += is_correct
                total_cases += 1
        
        accuracy = total_correct / total_cases
        print(f"\nğŸ¯ ìµœì¢… ì •í™•ë„: {total_correct}/{total_cases} = {accuracy:.3f} ({accuracy*100:.1f}%)")

if __name__ == "__main__":
    run_tests()