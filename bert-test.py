import torch
from transformers import AutoTokenizer, AutoModel
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

class BERTOnlyMatcher:
    def __init__(self):
        try:
            # í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ìš°ì„  ì‹œë„
            self.tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')
            self.model = AutoModel.from_pretrained('klue/bert-base')
            print("âœ… KLUE BERT ëª¨ë¸ ë¡œë”© ì„±ê³µ")
        except Exception as e:
            print(f"KLUE BERT ì‹¤íŒ¨: {e}")
            try:
                # ë‹¤êµ­ì–´ ëª¨ë¸ë¡œ ëŒ€ì²´
                self.tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')
                self.model = AutoModel.from_pretrained('bert-base-multilingual-cased')
                print("âœ… ë‹¤êµ­ì–´ BERT ëª¨ë¸ ë¡œë”© ì„±ê³µ")
            except Exception as e2:
                print(f"ëª¨ë“  BERT ëª¨ë¸ ì‹¤íŒ¨: {e2}")
                raise e2
    
    def get_embedding(self, text):
        """í…ìŠ¤íŠ¸ë¥¼ BERT ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)
        with torch.no_grad():
            outputs = self.model(**inputs)
        # [CLS] í† í°ì˜ ì„ë² ë”© ì‚¬ìš©
        return outputs.last_hidden_state[:, 0, :].numpy()
    
    def get_similarity(self, text1, text2):
        """ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        embedding1 = self.get_embedding(text1)
        embedding2 = self.get_embedding(text2)
        return cosine_similarity(embedding1, embedding2)[0][0]
    
    def is_related_product(self, title, keyword, threshold=0.5, debug=False):
        """BERT ìœ ì‚¬ë„ë§Œìœ¼ë¡œ ê´€ë ¨ ìƒí’ˆ íŒë‹¨"""
        similarity = self.get_similarity(title, keyword)
        
        if debug:
            print(f"    í‚¤ì›Œë“œ: '{keyword}'")
            print(f"    ìƒí’ˆëª…: '{title}'")
            print(f"    ìœ ì‚¬ë„: {similarity:.4f}")
            print(f"    ê²°ê³¼: {'âœ… ê´€ë ¨ìƒí’ˆ' if similarity >= threshold else 'âŒ ë¬´ê´€ìƒí’ˆ'}")
        
        return similarity >= threshold

# ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
def test_bert_matching():
    matcher = BERTOnlyMatcher()
    
    # ì‹¤ì œ ì‡¼í•‘ëª°ì—ì„œ ë‚˜ì˜¬ ë²•í•œ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        {
            "keyword": "ì½œë¼ê²ë§ˆìŠ¤í¬íŒ©",
            "products": [
                ("ì½œë¼ê² ì–¼êµ´ ë¹›ë‚˜ëŠ” í­ë°œ ë§ˆìŠ¤í¬ ìˆ˜ë¶„ íŒ©", True),  # ê´€ë ¨ìƒí’ˆ
                ("í”„ë¦¬ë¯¸ì—„ ì½œë¼ê² í˜ì´ì…œ ë§ˆìŠ¤í¬ 10ë§¤", True),     # ê´€ë ¨ìƒí’ˆ
                ("íˆì•Œë£¨ë¡ ì‚° ìˆ˜ë¶„ ë§ˆìŠ¤í¬íŒ© ëŒ€ìš©ëŸ‰", False),       # ì• ë§¤í•œ ì¼€ì´ìŠ¤
                ("ë¹„íƒ€ë¯¼C ë¸Œë¼ì´íŠ¸ë‹ ë§ˆìŠ¤í¬", False),             # ë¬´ê´€ìƒí’ˆ
                ("ì½œë¼ê² ì•°í”Œ ì—ì„¼ìŠ¤ ì„¸ëŸ¼", False),               # ë¬´ê´€ìƒí’ˆ (ë§ˆìŠ¤í¬íŒ© ì•„ë‹˜)
                ("ì²œì—° í—ˆë¸Œ í´ë Œì§• í¼", False),                  # ì™„ì „ ë¬´ê´€
            ]
        },
        {
            "keyword": "ë¬´ì„ ì´ì–´í°",
            "products": [
                ("ì• í”Œ ì—ì–´íŒŸ í”„ë¡œ ë¬´ì„  ì´ì–´í° 3ì„¸ëŒ€", True),
                ("ì‚¼ì„± ê°¤ëŸ­ì‹œ ë²„ì¦ˆ ë¸”ë£¨íˆ¬ìŠ¤ ì´ì–´í°", True), 
                ("ì†Œë‹ˆ ì™„ì „ë¬´ì„ ì´ì–´í° ë…¸ì´ì¦ˆìº”ìŠ¬ë§", True),
                ("ì  í•˜ì´ì € ìœ ì„  ì´ì–´í° ê³ ìŒì§ˆ", False),
                ("JBL ë¸”ë£¨íˆ¬ìŠ¤ ìŠ¤í”¼ì»¤ íœ´ëŒ€ìš©", False),
                ("ì•„ì´í° ì¶©ì „ê¸° ì¼€ì´ë¸”", False),
            ]
        },
        {
            "keyword": "ìš´ë™í™”",
            "products": [
                ("ë‚˜ì´í‚¤ ì—ì–´ë§¥ìŠ¤ ëŸ°ë‹í™” ë‚¨ì„±ìš©", True),
                ("ì•„ë””ë‹¤ìŠ¤ ìŠ¤ë‹ˆì»¤ì¦ˆ í™”ì´íŠ¸", True),
                ("ë‰´ë°œë€ìŠ¤ ì›Œí‚¹í™” í¸ì•ˆí•œ", True),
                ("ì»¨ë²„ìŠ¤ ìº”ë²„ìŠ¤í™” í´ë˜ì‹", True),
                ("êµ¬ë‘ ì •ì¥í™” ê°€ì£½ ë‚¨ì„±", False),
                ("ìŠ¬ë¦¬í¼ ì‹¤ë‚´í™” í¸í•œ", False),
            ]
        },
        {
            "keyword": "ë‹¤ì´ì–´íŠ¸ë³´ì¡°ì œ",
            "products": [
                ("ê°€ë¥´ì‹œë‹ˆì•„ ë‹¤ì´ì–´íŠ¸ ë³´ì¡°ì œ ìº¡ìŠ", True),
                ("ì²´ì§€ë°©ê°ì†Œ CLA ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ", True),
                ("L-ì¹´ë¥´ë‹ˆí‹´ ë‹¤ì´ì–´íŠ¸ ì„œí¬íŠ¸", True),
                ("í”„ë¡œí‹´ íŒŒìš°ë” ë‹¨ë°±ì§ˆ ë³´ì¶©ì œ", False),  # ì• ë§¤í•¨
                ("ì¢…í•©ë¹„íƒ€ë¯¼ ë©€í‹°ë¹„íƒ€ë¯¼", False),
                ("ê°ê¸°ì•½ ì¢…í•©ê°ê¸°", False),
            ]
        }
    ]
    
    # ë‹¤ì–‘í•œ ì„ê³„ê°’ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]
    
    print("=" * 80)
    print("BERT ìœ ì‚¬ë„ë§Œ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ë§¤ì¹­ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    for threshold in thresholds:
        print(f"\nğŸ“Š ì„ê³„ê°’: {threshold}")
        print("-" * 60)
        
        total_correct = 0
        total_cases = 0
        
        for test_case in test_cases:
            keyword = test_case["keyword"]
            print(f"\nğŸ” í‚¤ì›Œë“œ: '{keyword}'")
            
            for product_title, expected in test_case["products"]:
                similarity = matcher.get_similarity(product_title, keyword)
                predicted = similarity >= threshold
                is_correct = predicted == expected
                
                status = "âœ…" if is_correct else "âŒ"
                expected_str = "ê´€ë ¨" if expected else "ë¬´ê´€"
                predicted_str = "ê´€ë ¨" if predicted else "ë¬´ê´€"
                
                print(f"  {status} {similarity:.3f} | {expected_str}â†’{predicted_str} | {product_title[:40]}")
                
                total_correct += is_correct
                total_cases += 1
        
        accuracy = total_correct / total_cases
        print(f"\nğŸ¯ ì •í™•ë„: {total_correct}/{total_cases} = {accuracy:.3f} ({accuracy*100:.1f}%)")

# ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
def performance_comparison():
    """ê¸°ì¡´ ë°©ì‹ vs BERTë§Œ ì‚¬ìš© ì„±ëŠ¥ ë¹„êµ"""
    print("\n" + "="*80)
    print("ì„±ëŠ¥ ë¹„êµ: ê¸°ì¡´ í‚¤ì›Œë“œ ë§¤ì¹­ vs BERT ìœ ì‚¬ë„")
    print("="*80)
    
    matcher = BERTOnlyMatcher()
    
    # ì‹¤ì œ ë¬¸ì œê°€ ëë˜ ì¼€ì´ìŠ¤ë“¤
    problem_cases = [
        {
            "keyword": "ì½œë¼ê²ë§ˆìŠ¤í¬íŒ©",
            "titles": [
                "ì½œë¼ê² ì–¼êµ´ ë¹›ë‚˜ëŠ” í­ë°œ ë§ˆìŠ¤í¬ ìˆ˜ë¶„ íŒ©",  # í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œëŠ” ì–´ë ¤ì› ë˜ ì¼€ì´ìŠ¤
                "í”„ë¦¬ë¯¸ì—„ ê³¨ë“œ ì½œë¼ê² í˜ì´ì…œ ë§ˆìŠ¤í¬ ì‹œíŠ¸",
                "íˆì•Œë£¨ë¡ ì‚° ì½œë¼ê² ë³µí•© ë§ˆìŠ¤í¬íŒ© 10ë§¤",
            ]
        },
        {
            "keyword": "ë¸”ë£¨íˆ¬ìŠ¤ì´ì–´í°", 
            "titles": [
                "ë¬´ì„  ë¸”ë£¨íˆ¬ìŠ¤ ì´ì–´í° TWS ë…¸ì´ì¦ˆìº”ìŠ¬ë§",
                "ì—ì–´íŒŸ ìŠ¤íƒ€ì¼ ì™„ì „ë¬´ì„  ì´ì–´í°",
                "ê°¤ëŸ­ì‹œ ë²„ì¦ˆ í˜¸í™˜ ë¸”ë£¨íˆ¬ìŠ¤ í—¤ë“œì…‹",
            ]
        }
    ]
    
    for case in problem_cases:
        keyword = case["keyword"]
        print(f"\nğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ: '{keyword}'")
        print("-" * 50)
        
        for title in case["titles"]:
            similarity = matcher.get_similarity(title, keyword)
            print(f"ìœ ì‚¬ë„ {similarity:.3f} | {title}")
            
            # ì„ê³„ê°’ë³„ íŒì •
            for threshold in [0.4, 0.5, 0.6]:
                result = "ê´€ë ¨ìƒí’ˆ" if similarity >= threshold else "ë¬´ê´€ìƒí’ˆ"
                print(f"  - ì„ê³„ê°’ {threshold}: {result}")

if __name__ == "__main__":
    test_bert_matching()
    performance_comparison()